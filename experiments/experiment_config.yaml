# Experiment Configuration File

# Training Parameters
epochs: 50
batch_size: 128
learning_rate: 0.001
optimizer: 'adam'
validation_split: 0.1

# Datasets to test
datasets:
  # - 'mnist'
  # - 'fashion_mnist'
  - 'cifar10'
  # - 'cifar100'

# Models to test
models:
  # - 'alexnet_small'
  # - 'vgg16_small'
  # - 'efficientnet_small'
  # - 'efficientnetb1'
  # - 'resnet18'
  # - 'resnet50'
  # - 'resnet34'
  - 'resnet18v2'
  - 'resnet50v2'
  - 'resnet34v2'
  # - 'vgg11'
  # - 'vgg13'
  # - 'vgg16'
  # - 'vgg19'

# Activation functions to test
activations:
  - 'relu'
  - 'sigmoid'
  - 'tanh'
  - 'swish'
  - 'gelu'
  # - 'softmax'
  # - 'elu'
  # - 'mish'
  # - 'leaky_relu'
  # - 'selu'
  # - 'softsign_like'
  # - 'xtanh'
  # - 'sinusoidal'
  # - 'rsqrt_unit'
  # - 'softplus_relu'
  # - 'erf_act'
  # - 'snake_act'
  # - 'bent_identity'
  # - 'log_linear'
  # - 'hard_mish'
  # - 'tanh_shrink'

# Output directory
save_dir: 'cifar10_results'